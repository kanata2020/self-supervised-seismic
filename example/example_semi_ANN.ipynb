{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyNrdlh21yG/vna9IXpqNSLg"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["#data\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import scipy.io as io\n","from detection_XAI.utils import utils\n","import cv2\n","from tensorflow.keras.models import load_model\n","\n","x_cluster = io.loadmat('./SSL/data/x_cluster.mat')\n","x_cluster = x_cluster['x_cluster']\n","\n","# labells\n","y_cluster = io.loadmat('./SSL/data/y_cluster.mat')\n","y_cluster = y_cluster['y_cluster']\n","\n","#pre-processing\n","from keras.utils import to_categorical\n","\n","y_cluster_n = to_categorical(y_cluster-1)\n","x_cluster_n = utils.norml(x_cluster)\n","\n","x_cluster_stft = utils.batch_stft(x_cluster_n,nfft=128,overlap=0.7)\n","\n","#reshape input to 64x64\n","def resize_stft(x_in):\n","  batch_num = x_in.shape[0]\n","\n","  # Initialize an empty array to store resized images\n","  resized_input = np.zeros((batch_num, 64, 64, 3), dtype=np.float32)\n","\n","  # Loop through each image in the batch and resize\n","  for i in range(batch_num):\n","      # Resize each image to (64, 64)\n","      resized_image = cv2.resize(x_in[i], (64, 64), interpolation=cv2.INTER_LINEAR)\n","\n","      # Store the resized image in the new array\n","      resized_input[i] = resized_image\n","\n","\n","# Now 'resized_images' contains all the images resized to (64, 64, 3) with dtype float32\n","  return resized_input\n","\n","resized_x = resize_stft(x_cluster_stft)\n","\n","saved_encoder_model = load_model(\"./SSL/model/encoder_4x4x16_v2.h5\")\n","encoded_features = saved_encoder_model.predict(resized_x)\n","reshaped_features = encoded_features.reshape(encoded_features.shape[0], -1)"],"metadata":{"id":"cHRZByoMpmJ1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1718627338188,"user_tz":-60,"elapsed":27562,"user":{"displayName":"神奈川彼方","userId":"07553042853244915746"}},"outputId":"99a6ee69-89a9-4755-c8e0-42b83a257ea5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"]},{"output_type":"stream","name":"stdout","text":["43/43 [==============================] - 2s 8ms/step\n"]}]},{"cell_type":"code","source":["# train the model\n","import tensorflow as tf\n","from tensorflow.keras.utils import to_categorical\n","from sklearn.model_selection import train_test_split\n","\n","\n","# Define the model architecture\n","def create_model(input_shape):\n","    model = tf.keras.models.Sequential([\n","        tf.keras.layers.Dense(128, activation='relu', input_shape=input_shape),\n","        tf.keras.layers.Dropout(0.2),\n","        tf.keras.layers.Dense(64, activation='relu'),\n","        tf.keras.layers.Dropout(0.2),\n","        tf.keras.layers.Dense(32, activation='relu'),\n","        tf.keras.layers.Dropout(0.2),\n","        tf.keras.layers.Dense(4, activation='softmax')  # Assuming 4 classes\n","    ])\n","    return model\n","\n","# Create the model\n","model = create_model(input_shape=(256,))\n","\n","# Compile the model\n","model.compile(optimizer='adam',\n","              loss='categorical_crossentropy',\n","              metrics=['accuracy'])\n","\n","# Print the model summary\n","model.summary()"],"metadata":{"id":"lAnBqiTW4_XF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1718632960436,"user_tz":-60,"elapsed":496,"user":{"displayName":"神奈川彼方","userId":"07553042853244915746"}},"outputId":"37423c7f-3ff1-4231-ca80-f0433ec50485"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_79\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_316 (Dense)           (None, 128)               32896     \n","                                                                 \n"," dropout_237 (Dropout)       (None, 128)               0         \n","                                                                 \n"," dense_317 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_238 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_318 (Dense)           (None, 32)                2080      \n","                                                                 \n"," dropout_239 (Dropout)       (None, 32)                0         \n","                                                                 \n"," dense_319 (Dense)           (None, 4)                 132       \n","                                                                 \n","=================================================================\n","Total params: 43364 (169.39 KB)\n","Trainable params: 43364 (169.39 KB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["# Convert labels to one-hot encoded matrix\n","y_train_one_hot = to_categorical(y_train - 1)  # Subtract 1 because indices start from 0\n","y_test_one_hot = to_categorical(y_test - 1)\n","# Train the model\n","model.fit(X_train, y_train_one_hot, epochs=200, batch_size=128, validation_data=(X_test, y_test_one_hot), verbose=1)"],"metadata":{"id":"3a3RsLgj-Xkn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.metrics import accuracy_score\n","from sklearn.metrics import confusion_matrix\n","from sklearn.metrics import classification_report\n","from sklearn.metrics import precision_recall_fscore_support\n","\n","def resultshow(classes,label):\n","  lis=np.zeros(classes.shape[0])\n","  for i in range(classes.shape[0]):\n","   jeg = np.where(classes[i,:] == max(classes[i,:]))\n","   lis[i] = jeg[0]\n","\n","  tru=np.zeros(classes.shape[0])\n","  for i in range(classes.shape[0]):\n","    jeg2 = np.where(label[i,:] == max(label[i,:]))\n","    tru[i] = jeg2[0]\n","\n","  target = ['quake','earthquake','rockfall','enviroemnt noise']\n","  print(classification_report(tru, lis, target_names=target))\n","  print(confusion_matrix(tru, lis))\n","  confusion_matrices = (confusion_matrix(tru, lis))\n","  precision, recall, f1, support = precision_recall_fscore_support(tru, lis)\n","  return confusion_matrices, precision, recall, f1"],"metadata":{"id":"4TLhN--9Rqbo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split, StratifiedKFold\n","from sklearn.metrics import classification_report, precision_recall_fscore_support\n","from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n","\n","# K-fold validation (3-fold in this example)\n","kfold = StratifiedKFold(n_splits=3, shuffle=True)\n","data = reshaped_features\n","labels = y_cluster.flatten()\n","\n","class_names = ['quake', 'earthquake', 'rockfall', 'noise']\n","precision_dicts = {class_name: [] for class_name in class_names}\n","recall_dicts = {class_name: [] for class_name in class_names}\n","f1_dicts = {class_name: [] for class_name in class_names}\n","confusion_matrices_list = []\n","accuracy_list = []\n","\n","for train_index, test_index in kfold.split(data, labels):\n","    X_test, X_train = data[train_index], data[test_index]\n","    y_test, y_train = labels[train_index], labels[test_index]\n","    y_train_one_hot = to_categorical(y_train - 1)  # Subtract 1 because indices start from 0\n","    y_test_one_hot = to_categorical(y_test - 1)\n","\n","    model = create_model(input_shape=(256,))\n","    # Compile the model\n","    model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n","    model.fit(X_train, y_train_one_hot, epochs=200, batch_size=128, validation_data=(X_test, y_test_one_hot), verbose=0)\n","\n","    results = model.predict(X_test)\n","    confusion_matrices, precision, recall, f1 = resultshow(results,y_test_one_hot)\n","    confusion_matrices_list.append(confusion_matrices)\n","\n","    # Calculate accuracy for the current fold\n","    _, accuracy = model.evaluate(X_test, y_test_one_hot, verbose=0)\n","    accuracy_list.append(accuracy)\n","\n","            # Update dictionaries for each class\n","    for class_name in class_names:\n","        class_index = class_names.index(class_name)\n","        precision_dicts[class_name].append(precision[class_index])\n","        recall_dicts[class_name].append(recall[class_index])\n","        f1_dicts[class_name].append(f1[class_index])\n","\n","# Calculate mean and std for each class\n","for class_name in class_names:\n","    mean_precision = np.mean(precision_dicts[class_name])\n","    std_precision = np.std(precision_dicts[class_name])\n","\n","    mean_recall = np.mean(recall_dicts[class_name])\n","    std_recall = np.std(recall_dicts[class_name])\n","\n","    mean_f1 = np.mean(f1_dicts[class_name])\n","    std_f1 = np.std(f1_dicts[class_name])\n","\n","    # Print mean and std for each class\n","    print(f\"Class {class_name} - Mean Precision: {mean_precision:.3f} ± {std_precision:.3f}\")\n","    print(f\"Class {class_name} - Mean Recall: {mean_recall:.3f} ± {std_recall:.3f}\")\n","    print(f\"Class {class_name} - Mean F1-score: {mean_f1:.3f} ± {std_f1:.3f}\")\n","\n","# Calculate and print mean and std for accuracy\n","mean_accuracy = np.mean(accuracy_list)\n","std_accuracy = np.std(accuracy_list)\n","\n","print(f\"Mean Accuracy: {mean_accuracy:.3f} ± {std_accuracy:.3f}\")"],"metadata":{"id":"FEnuq8bMHLie","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1718633023162,"user_tz":-60,"elapsed":57715,"user":{"displayName":"神奈川彼方","userId":"07553042853244915746"}},"outputId":"b9cbf69f-4da8-4364-b3c6-14d0c0d6798c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["29/29 [==============================] - 0s 2ms/step\n","                  precision    recall  f1-score   support\n","\n","           quake       0.81      0.71      0.75       156\n","      earthquake       0.95      0.93      0.94       259\n","        rockfall       0.94      0.92      0.93       268\n","enviroemnt noise       0.80      0.91      0.85       233\n","\n","        accuracy                           0.88       916\n","       macro avg       0.87      0.86      0.87       916\n","    weighted avg       0.88      0.88      0.88       916\n","\n","[[110   5   6  35]\n"," [  8 240   4   7]\n"," [  8   3 246  11]\n"," [ 10   5   7 211]]\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-24-0dae81680718>:10: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n","  lis[i] = jeg[0]\n","<ipython-input-24-0dae81680718>:15: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n","  tru[i] = jeg2[0]\n"]},{"output_type":"stream","name":"stdout","text":["29/29 [==============================] - 0s 3ms/step\n","                  precision    recall  f1-score   support\n","\n","           quake       0.75      0.81      0.78       156\n","      earthquake       0.95      0.91      0.93       259\n","        rockfall       0.90      0.93      0.91       268\n","enviroemnt noise       0.87      0.82      0.85       234\n","\n","        accuracy                           0.88       917\n","       macro avg       0.87      0.87      0.87       917\n","    weighted avg       0.88      0.88      0.88       917\n","\n","[[126   5   7  18]\n"," [ 10 236  11   2]\n"," [  6   4 250   8]\n"," [ 26   4  11 193]]\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-24-0dae81680718>:10: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n","  lis[i] = jeg[0]\n","<ipython-input-24-0dae81680718>:15: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n","  tru[i] = jeg2[0]\n"]},{"output_type":"stream","name":"stdout","text":["29/29 [==============================] - 0s 3ms/step\n","                  precision    recall  f1-score   support\n","\n","           quake       0.77      0.81      0.79       156\n","      earthquake       0.90      0.92      0.91       260\n","        rockfall       0.86      0.92      0.89       268\n","enviroemnt noise       0.91      0.78      0.84       233\n","\n","        accuracy                           0.86       917\n","       macro avg       0.86      0.86      0.86       917\n","    weighted avg       0.87      0.86      0.86       917\n","\n","[[126  10   6  14]\n"," [  7 240  12   1]\n"," [  6  13 246   3]\n"," [ 24   5  23 181]]\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-24-0dae81680718>:10: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n","  lis[i] = jeg[0]\n","<ipython-input-24-0dae81680718>:15: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n","  tru[i] = jeg2[0]\n"]},{"output_type":"stream","name":"stdout","text":["Class quake - Mean Precision: 0.777 ± 0.024\n","Class quake - Mean Recall: 0.774 ± 0.048\n","Class quake - Mean F1-score: 0.774 ± 0.015\n","Class earthquake - Mean Precision: 0.931 ± 0.025\n","Class earthquake - Mean Recall: 0.920 ± 0.007\n","Class earthquake - Mean F1-score: 0.925 ± 0.012\n","Class rockfall - Mean Precision: 0.896 ± 0.032\n","Class rockfall - Mean Recall: 0.923 ± 0.007\n","Class rockfall - Mean F1-score: 0.909 ± 0.017\n","Class noise - Mean Precision: 0.861 ± 0.046\n","Class noise - Mean Recall: 0.836 ± 0.053\n","Class noise - Mean F1-score: 0.845 ± 0.005\n","Mean Accuracy: 0.875 ± 0.007\n"]}]},{"cell_type":"code","source":["confusion_matrices_array = np.array(confusion_matrices_list)\n","\n","mean_confusion_matrix = np.mean(confusion_matrices_array, axis=0)\n","std_confusion_matrix = np.std(confusion_matrices_array, axis=0)\n","\n","\n","print(\"Mean Confusion Matrix:\")\n","print(mean_confusion_matrix)\n","print(\"\\nStandard Deviation Confusion Matrix:\")\n","print(std_confusion_matrix)"],"metadata":{"id":"Y4kUXb9jUEjg","executionInfo":{"status":"ok","timestamp":1718633043318,"user_tz":-60,"elapsed":658,"user":{"displayName":"神奈川彼方","userId":"07553042853244915746"}},"outputId":"ae0bcde2-b486-44c5-d544-84746fb03bdf","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mean Confusion Matrix:\n","[[120.66666667   6.66666667   6.33333333  22.33333333]\n"," [  8.33333333 238.66666667   9.           3.33333333]\n"," [  6.66666667   6.66666667 247.33333333   7.33333333]\n"," [ 20.           4.66666667  13.66666667 195.        ]]\n","\n","Standard Deviation Confusion Matrix:\n","[[ 7.54247233  2.3570226   0.47140452  9.10433352]\n"," [ 1.24721913  1.88561808  3.55902608  2.62466929]\n"," [ 0.94280904  4.49691252  1.88561808  3.29983165]\n"," [ 7.11805217  0.47140452  6.79869268 12.32882801]]\n"]}]}]}